{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_excel('balanced_all_data_1_bar.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggregated_database(input_file: str, output_file: str, pattern_quantity: int, inclusive: bool = False):\n",
    "    \"\"\"\n",
    "    Create a new database by aggregating sequences of MIDI patterns from the same file.\n",
    "    Supports both non-overlapping and overlapping (inclusive) combinations.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the input Excel file.\n",
    "        output_file (str): Path to save the output Excel file.\n",
    "        pattern_quantity (int): Number of patterns to combine into a single row.\n",
    "        inclusive (bool): Whether to use overlapping combinations. Default is False.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Read the input file\n",
    "    data = pd.read_excel(input_file)\n",
    "    \n",
    "    # Validate that required columns exist\n",
    "    required_columns = {\"file\", \"sequence\", \"class\"}\n",
    "    step_columns = {f\"step_{i}\" for i in range(16)}\n",
    "    all_columns = required_columns.union(step_columns)\n",
    "    if not all_columns.issubset(data.columns):\n",
    "        raise ValueError(f\"Input dataset must contain the columns: {all_columns}\")\n",
    "\n",
    "    # Initialize a list to store new rows\n",
    "    new_rows = []\n",
    "    \n",
    "    # Group rows by the `file` column to ensure blending happens only within the same file\n",
    "    for file, group in data.groupby(\"file\"):\n",
    "        # Sort by sequence to ensure correct order\n",
    "        group = group.sort_values(\"sequence\")\n",
    "        \n",
    "        # Determine the step size for the sliding window\n",
    "        step_size = 1 if inclusive else pattern_quantity\n",
    "        num_rows = len(group)\n",
    "        \n",
    "        # Iterate over the group with a sliding window\n",
    "        for i in range(0, num_rows - pattern_quantity + 1, step_size):\n",
    "            chunk = group.iloc[i:i+pattern_quantity]\n",
    "            \n",
    "            # Aggregate the data\n",
    "            aggregated_row = {\n",
    "                \"file\": file,\n",
    "                \"sequence\": \"-\".join(map(str, chunk[\"sequence\"])),\n",
    "                \"class\": chunk[\"class\"].iloc[0]  # All rows in the chunk should have the same class\n",
    "            }\n",
    "            \n",
    "            # Validate that all rows in the chunk belong to the same class\n",
    "            if len(chunk[\"class\"].unique()) > 1:\n",
    "                raise ValueError(f\"Found multiple classes in the same file ({file}).\")\n",
    "\n",
    "            # Concatenate the features from each row in the chunk\n",
    "            for j, row in enumerate(chunk.itertuples(index=False)):\n",
    "                for k in range(16):  # Each sequence has 16 features\n",
    "                    feature_name = f\"feature_{j * 16 + k}\"\n",
    "                    aggregated_row[feature_name] = getattr(row, f\"step_{k}\")\n",
    "            \n",
    "            # Add the new row to the list\n",
    "            new_rows.append(aggregated_row)\n",
    "    \n",
    "    # Create a new DataFrame and save it to an Excel file\n",
    "    new_data = pd.DataFrame(new_rows)\n",
    "    new_data.to_excel(output_file, index=False)\n",
    "    print(f\"New database saved to {output_file}\")\n",
    "\n",
    "# # Example usage:\n",
    "# # Non-overlapping (default)\n",
    "# create_aggregated_database(\"input_dataset.xlsx\", \"output_dataset_non_overlapping.xlsx\", pattern_quantity=2)\n",
    "\n",
    "# # Overlapping (inclusive=True)\n",
    "# create_aggregated_database(\"input_dataset.xlsx\", \"output_dataset_inclusive.xlsx\", pattern_quantity=2, inclusive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New database saved to data_pattern_4_inclusive_balanced.xlsx\n"
     ]
    }
   ],
   "source": [
    "# create_aggregated_database(\"fwod_representations_clean.xlsx\", \"data_pattern_2.xlsx\", pattern_quantity=2)\n",
    "create_aggregated_database(\"balanced_all_data_1_bar.xlsx\", \"data_pattern_4_inclusive_balanced.xlsx\", pattern_quantity=4, inclusive=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-macos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
